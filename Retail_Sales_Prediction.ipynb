{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "MSa1f5Uengrz",
        "U560ucMGaI1Q",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "id1riN9m0vUs",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "dJ2tPlVmpsJ0"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arsudsandesh97/Retail-Sales-Prediction/blob/main/Retail_Sales_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Retail Sales Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name -** Sandesh Sundarlal Arsud"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Rossmann dataset contains 9 columns and 1,017,209 rows of data. This dataset likely pertains to sales at Rossmann drugstores, with columns such as the store number, date, sales, and customer count. To analyze this dataset, one could use exploratory data analysis techniques to gain insight into trends and seasonality in the data. Exponential moving averages could be used to identify trends, while seasonal decomposition could be used to identify seasonal patterns.\n",
        "\n",
        "Additionally, regression analysis could be performed to predict sales based on the data in the Rossmann dataset. Three types of regression analysis that could be used are linear regression, lasso regression, and ridge regression. Linear regression would be useful for modeling the relationship between sales and one or more predictor variables. Lasso and ridge regression are useful when dealing with datasets that have high levels of multicollinearity, as they can help to identify the most important predictors and prevent overfitting.\n",
        "\n",
        "The second dataset is the Store dataframe, which has 10 columns and 1115 rows. It is unclear what this dataset pertains to, but it likely contains information about different stores, such as their location, size, and number of employees. Further analysis would be needed to determine the appropriate statistical techniques to use with this dataset."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/arsudsandesh97/Retail-Sales-Prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The problem at hand is to predict the daily sales of Rossmann drugstores across seven European countries for up to six weeks in advance. This is a challenging task as there are numerous factors that can influence store sales, including promotional activities, competition, holidays, seasonality, and location. Currently, store managers are tasked with predicting sales based on their unique circumstances, resulting in varying levels of accuracy.\n",
        "\n",
        "To address this issue, historical sales data for 1,115 Rossmann stores has been provided, and the goal is to use this data to forecast the \"Sales\" column for the test set. It should be noted that some stores in the dataset were temporarily closed for refurbishment, which may have an impact on the accuracy of the predictions.\n",
        "\n",
        "This problem presents a unique challenge as it requires the development of a forecasting model that can account for the complex and dynamic factors that influence sales at Rossmann drugstores. The successful implementation of such a model could lead to more accurate sales predictions, enabling Rossmann to better plan and allocate resources across its stores "
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ros_df = pd.read_csv('/content/drive/MyDrive/project/Retail Sales Prediction/Rossmann Stores Data.csv')\n",
        "store_df = pd.read_csv('/content/drive/MyDrive/project/Retail Sales Prediction/store.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "ros_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "store_df.head()"
      ],
      "metadata": {
        "id": "qGvv-fIUDfJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "ros_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "store_df.shape"
      ],
      "metadata": {
        "id": "uIZ7NywcDr1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "ros_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "store_df.info()"
      ],
      "metadata": {
        "id": "p5z96FkdD12g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(ros_df[ros_df.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(store_df[ros_df.duplicated()])"
      ],
      "metadata": {
        "id": "clEnrK8WD-k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "ros_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ros_df.isnull().columns"
      ],
      "metadata": {
        "id": "LYVLYQWZEAx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(ros_df.isnull(), cmap='Blues', cbar=False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "store_df.isnull().sum()"
      ],
      "metadata": {
        "id": "lW_Qyt21ELJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(store_df.isnull(),cmap='Purples', cbar=False)"
      ],
      "metadata": {
        "id": "rPSWV-RzEV8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Rossman Dataset : The dataset contains several columns with missing or null values. These columns are 'Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', and 'SchoolHoliday'.\n",
        "\n",
        "* Store Dataset : The dataset appears to contain several columns with missing \n",
        "values or null values. These columns are 'Store', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', and 'PromoInterval'."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "\n",
        "ros_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "\n",
        "store_df.columns"
      ],
      "metadata": {
        "id": "_RYyEP7-Ekr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "\n",
        "ros_df.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "\n",
        "store_df.describe(include='all')"
      ],
      "metadata": {
        "id": "IDV8xKRvEtsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ros_df.columns"
      ],
      "metadata": {
        "id": "qlOM_U5zgyBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rossman Dataset**\n",
        "\n",
        "* Store : Identifier for each store\n",
        "\n",
        "* DayOfWeek : The day of the week, with Monday being 1 and Sunday being 7\n",
        "\n",
        "* Sales : The amount of sales made at the store on that day\n",
        "\n",
        "* Customers : The number of customers who visited the store on that day\n",
        "\n",
        "* Open : Indicator of whether the store was open on that day (0 or 1)\n",
        "\n",
        "* Promo : Indicator of whether there was a promotion taking place at the store on that day (0 or 1)\n",
        "\n",
        "* SchoolHoliday : Indicator of whether it was a school holiday on that day (0 or 1)\n",
        "\n",
        "\n",
        "\n",
        "**The statistics provided for each variable are:**\n",
        "\n",
        "* Count: Total number of records\n",
        "\n",
        "* Mean: Average value of the variable\n",
        "\n",
        "* Standard Deviation: Measure of the spread of the variable's values\n",
        "\n",
        "* Minimum: Smallest value in the variable\n",
        "\n",
        "* 25th Percentile: Value below which 25% of the variable's values fall\n",
        "\n",
        "* Median (50th Percentile): Middle value of the variable\n",
        "\n",
        "* 75th Percentile: Value below which 75% of the variable's values fall\n",
        "\n",
        "* Maximum: Largest value in the variable\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Store Dataset**\n",
        "\n",
        "**This data set includes information about different stores, including the following variables:**\n",
        "\n",
        "* Store: Identifier for each store\n",
        "\n",
        "* CompetitionDistance: The distance of the nearest competitor from the store\n",
        "\n",
        "* CompetitionOpenSinceMonth: Month the nearest competitor was opened\n",
        "\n",
        "* CompetitionOpenSinceYear: Year the nearest competitor was opened\n",
        "\n",
        "* Promo2: Indicator of whether the store is running a promotion\n",
        "\n",
        "* Promo2SinceWeek: Week the store started running the promotion\n",
        "\n",
        "* Promo2SinceYear: Year the store started running the promotion\n",
        "\n",
        "\n",
        "**The statistics provided give an overview of the distribution of each variable's values.**\n",
        "\n",
        "* The data for the variables \"CompetitionDistance\" has a mean of 5404.90, std dev of 7663.17, and a range of 20 to 75860 with 3 missing values.\n",
        "\n",
        "* \"CompetitionOpenSinceMonth\" and \"CompetitionOpenSinceYear\" have means of 7.22 and 2008.67, std dev of 3.21 and 6.20, and ranges of 1-12 and 1900-2015 with 354 missing values.\n",
        "\n",
        "* \"Promo2\" has a mean of 0.51 and no missing values, while \"Promo2SinceWeek\" and \n",
        "\n",
        "* \"Promo2SinceYear\" have means of 23.60 and 2011.76, std dev of 14.14 and 1.67, and ranges of 1-50 and 2009-2015 with 544 missing values."
      ],
      "metadata": {
        "id": "dlSIfijXjDV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "for i in ros_df.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",ros_df[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "for i in store_df.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",store_df[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "_ErxktFNE4ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Convert data types for columns as needed\n",
        "# ros_df['Date'] = pd.to_datetime(ros_df['Date'])\n",
        "ros_df['StateHoliday'] = ros_df['StateHoliday'].astype('category')\n",
        "\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data types for columns as needed\n",
        "store_df['StoreType'] = store_df['StoreType'].astype('category')\n",
        "store_df['Assortment'] = store_df['Assortment'].astype('category')"
      ],
      "metadata": {
        "id": "gFBTE79FHWrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ros_df.columns"
      ],
      "metadata": {
        "id": "PjDSc2vsb7Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract year, month, day and week of year from \"Date\"\n",
        "\n",
        "ros_df['Date']=pd.to_datetime(ros_df['Date'])\n",
        "ros_df['Year'] = ros_df['Date'].apply(lambda x: x.year)\n",
        "ros_df['Month'] = ros_df['Date'].apply(lambda x: x.month)"
      ],
      "metadata": {
        "id": "4iVFwg9wBBFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns as needed\n",
        "\n",
        "ros_df.rename(columns={'CompetitionDistance': 'DistanceToNearestCompetitor',\n",
        "'CompetitionOpenSinceMonth': 'CompetitorOpenMonth',\n",
        "'CompetitionOpenSinceYear': 'CompetitorOpenYear'}, inplace=True)"
      ],
      "metadata": {
        "id": "ruC_kS2mIs1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ros_df = ros_df.drop(['Date'],axis=1)"
      ],
      "metadata": {
        "id": "-E7ZBvi3EyBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove features\n",
        "store_df = store_df.drop(['CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear','Promo2SinceWeek',\n",
        "                     'Promo2SinceYear', 'PromoInterval'], axis=1)"
      ],
      "metadata": {
        "id": "3tREg9ycYLie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CompetitionDistance is distance in meters to the nearest competitor store\n",
        "# let's first have a look at its distribution\n",
        "\n",
        "sns.distplot(store_df.CompetitionDistance.dropna())\n",
        "plt.title(\"Distributin of Store Competition Distance\")"
      ],
      "metadata": {
        "id": "G4G6oNbtYpQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace missing values in CompetitionDistance with median for the store dataset\n",
        "\n",
        "store_df.CompetitionDistance.fillna(store_df.CompetitionDistance.median(), inplace=True)"
      ],
      "metadata": {
        "id": "2XpJZbmSY0KL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "\n",
        "correlation_map = ros_df[ros_df.columns].corr()\n",
        "obj = np.array(correlation_map)\n",
        "obj[np.tril_indices_from(obj)] = False\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(9, 9)\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "sns.heatmap(correlation_map, mask=obj, vmax=.7, square=True, annot=True, cmap=cmap)\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I choosed this chart because The heatmap is a suitable choice for this task because it allows for a quick and intuitive understanding of the strength and direction of the correlation between pairs of variables. The use of colors and annotations in the heatmap further enhances the interpretation of the correlation matrix."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights from a heatmap chart of a correlation matrix can provide valuable information about the relationships between variables in a dataset. By examining the color intensity and values displayed in the grid, one can identify the strengths of the correlations between the variables, with stronger correlations being represented by brighter colors and larger values. However, it is important to keep in mind that correlation does not necessarily imply causation, and that other factors may be at play in determining the relationships between the variables. Nevertheless, analyzing the correlations between variables can be a useful starting point for identifying interesting patterns and relationships in a dataset."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "\n",
        "fig = px.histogram(ros_df, x='DayOfWeek', color='Open')\n",
        "fig.update_traces(marker_line_width=0.5, opacity=0.7)\n",
        "fig.update_layout(\n",
        "    title='Open vs Closed Stores by Day of Week',\n",
        "    xaxis_title='Day of Week',\n",
        "    yaxis_title='Count',\n",
        "    legend_title='Open',\n",
        "    barmode='group',\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "histogram with color encoding, which is a useful type of visualization to compare the distribution of a numerical variable across different groups. In this case, the chart is comparing the distribution of store opening and closing by day of the week, which could be useful for understanding patterns of customer demand or store performance."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "insights found from above chart that is the saturday is the day have maximum stores is open after that sunday have less number of store is open"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "custom_colors = ['#0096c7', '#ffcc99']\n",
        "\n",
        "Promo_sales = pd.DataFrame(ros_df.groupby('Promo').agg({'Sales':'mean'}))\n",
        "\n",
        "fig = go.Figure(\n",
        "    data=[go.Bar(x=Promo_sales.index, y=Promo_sales['Sales'], marker_color=custom_colors)],\n",
        "    layout=go.Layout(\n",
        "        title='Average Sales by Promo',\n",
        "        xaxis_title='Promo',\n",
        "        yaxis_title='Average Sales',\n",
        "    )\n",
        ")\n",
        "fig.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart is a good choice for this type of data because it allows for easy comparison of mean sales across categorical data, while the use of custom colors can enhance visual appeal and highlight important information."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "insight found in above chart is average sales by promo which is sales of 4.406.051 and 1.7.991.152"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "custom_palette = ['#8E44AD']\n",
        "sns.set_palette(custom_palette)\n",
        "\n",
        "sns.factorplot(x=\"Month\", y=\"Sales\", data=ros_df, kind=\"point\", aspect=2, size=10)\n",
        "\n",
        "sns.despine()\n",
        "plt.title('Monthly Sales')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Sales')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The factor plot is used because good way to show the relationship between a categorical variable (month) and a continuous variable (sales). Adjusting the plot's size, aspect ratio, and color palette can make it more visually appealing and emphasize the main message of the plot."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above chart reveals that the highest number of sales occurred in December, while the lowest number of sales occurred in January and May. "
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# Define the data and labels\n",
        "labels = ['Not-Affected', 'Affected']\n",
        "sizes = ros_df.SchoolHoliday.value_counts()\n",
        "explode = (0.1, 0.0)\n",
        "\n",
        "# Define the colors\n",
        "colors = ['#4CAF50', '#FF5722']  # Green and Orange\n",
        "\n",
        "# Create the pie chart\n",
        "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
        "        autopct='%1.1f%%', shadow=True, startangle=180)\n",
        "\n",
        "# Set the title and other properties\n",
        "plt.axis('equal')\n",
        "plt.title(\"Sales Affected by School Holiday or Not?\", fontsize=20)\n",
        "plt.plot()\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(6, 6)\n",
        "\n",
        "# Show the chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosed this chart beacuse the pie chart shows the proportion of sales affected or not affected by school holidays, making it a useful way to compare the relative sizes of different categories."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the above chart, 17.9% of sales are affected by the school holiday, while 82.1% are not affected. "
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Create the distribution plot\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(11, 7)\n",
        "sns.distplot(ros_df['Sales'], kde=False, bins=40, color='#FF5722')  # Use Orange color\n",
        "\n",
        "# Set the title and other properties\n",
        "ax.set_xlabel('Sales', fontsize=15)\n",
        "ax.set_ylabel('Count', fontsize=15)\n",
        "ax.set_title('Distribution of Sales', fontsize=20)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose this chart because a distribution plot (histogram) is a common type of chart used to visualise the distribution of a numerical variable. In this case, it can be useful to understand the distribution of sales in the dataset and identify any outliers or unusual patterns in the data."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight found from the above chart is that the majority of sales are concentrated at the lower end of the distribution, with fewer sales at higher values. This suggests that the distribution of sales is right-skewed, meaning that there are a few very high values that pull the mean towards the right while most of the data is concentrated at lower values."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Create the scatter plot with linear regression line\n",
        "sns.lmplot(x='Sales', y='Customers', data=ros_df, palette='viridis', height=5, aspect=1, line_kws={'color': '#FF5722'})\n",
        "\n",
        "# Set the title and other properties\n",
        "plt.title('Linear Relationship between Sales and Customers', fontsize=20)\n",
        "plt.xlabel('Sales', fontsize=15)\n",
        "plt.ylabel('Customers', fontsize=15)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "chose this chart because A scatter plot with a linear regression line is used to show the relationship between two continuous variables, sales and customers. It helps identify any differences across different subsets of the data."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows a positive linear relationship between sales and customers, suggesting that as the number of customers increases, so do the sales. The scatter plot also reveals some variations in the relationship between sales and customers across different store types, with some store types having a stronger relationship than others."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization for store dataset"
      ],
      "metadata": {
        "id": "Njfx_jALZCFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "#pairplot for store dataset\n",
        "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
        "pp=sns.pairplot(store_df,hue='StoreType')\n",
        "pp.fig.set_size_inches(10,10);"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the pair plot because pair plots are used to visualise pairwise relationships between variables in a dataset to identify patterns, correlations, and outliers."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "identified patterns, correlations, or outliers between different pairs of variables in a dataset. By visualising these pairwise relationships, a pair plot helps identify potential areas for further analysis or investigation."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "\n",
        "#checking stores with their assortment type \n",
        "sns.set_style(\"whitegrid\")\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(11, 7)\n",
        "store_type=sns.countplot(x='StoreType',hue='Assortment', data=store_df,palette=\"inferno\")\n",
        "\n",
        "for p in store_type.patches:\n",
        "    store_type.annotate(f'\\n{p.get_height()}', (p.get_x()+0.15, p.get_height()),ha='center', va='top', color='white', size=10)"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose countplot because it is a useful tool to visualise the frequency distribution of the categorical variables StoreType and Assortment, segmented by Assortment, and with annotations added to provide more detailed information."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above chart reveals an insight: on the countplot, StoreType 'a' has the most stores, and the majority of these stores have Assortment Type 'a'. StoreType 'd' has the fewest stores, and the stores are distributed evenly among Assortment Types 'a', 'b', and 'c'. This information can be useful in making decisions about product assortment and marketing strategies for different store types."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Merging Two datasets**"
      ],
      "metadata": {
        "id": "U560ucMGaI1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.merge(ros_df, store_df, how='left', on='Store')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "v08e6EsYaVm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "UV2_ZVFoaekj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Check for missing values in the dataset\n",
        "df.isnull().sum()\n",
        "\n",
        "# Replace missing values in 'Sales' column with the mean value\n",
        "df['Sales'].fillna((df['Sales'].mean()), inplace=True)\n",
        "\n",
        "# Replace missing values in 'Customers' column with the mean value\n",
        "df['Customers'].fillna((df['Customers'].mean()), inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Check for missing values after imputation\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "#checking outliers in sales\n",
        "sns.boxplot(ros_df['Sales'])"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing outliers\n",
        "def remove_outlier(df_in, col_name):\n",
        "    q1 = df_in[col_name].quantile(0.25)\n",
        "    q3 = df_in[col_name].quantile(0.75)\n",
        "    iqr = q3-q1 #Interquartile range\n",
        "    fence_low  = q1-1.5*iqr\n",
        "    fence_high = q3+1.5*iqr\n",
        "    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n",
        "    return df_out"
      ],
      "metadata": {
        "id": "98QAHPaXb7md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining new variable after removing outliers\n",
        "df= remove_outlier(df, 'Sales')"
      ],
      "metadata": {
        "id": "e7mHuD1YcOZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "\n",
        "# Select the categorical columns to encode\n",
        "df['DayOfWeek'] = df['DayOfWeek'].astype(int)\n",
        "\n",
        "cat_cols = ['DayOfWeek', 'StateHoliday', 'SchoolHoliday','StoreType', 'Assortment']\n",
        "\n",
        "# Apply one-hot encoding to the categorical columns\n",
        "df_encoded = pd.get_dummies(df, columns=cat_cols,drop_first=True)\n",
        "\n",
        "# Show the encoded dataset\n",
        "df_encoded.head()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for changing Assortment dtype from float to int.\n",
        "df['CompetitionDistance']= df['CompetitionDistance'].astype(int)"
      ],
      "metadata": {
        "id": "BrgEQlVtj68m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for changing Assortment dtype from object to int.\n",
        "df['Assortment'] = np.where((df['Assortment'] == 'a'),0,df['Assortment'])\n",
        "df['Assortment'] = np.where((df['Assortment'] == 'b'),1,df['Assortment'])\n",
        "df['Assortment'] = np.where((df['Assortment'] == 'c'),2,df['Assortment'])"
      ],
      "metadata": {
        "id": "avV5r7V0UzV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting catagorical value into interger values based on store type class.\n",
        "df['StoreType'] = np.where((df['StoreType'] == 'b'),1,df['StoreType'])\n",
        "df['StoreType'] = np.where((df['StoreType'] == 'c'),2,df['StoreType'])\n",
        "df['StoreType'] = np.where((df['StoreType'] == 'a'),0,df['StoreType'])\n",
        "df['StoreType'] = np.where((df['StoreType'] == 'd'),3,df['StoreType'])"
      ],
      "metadata": {
        "id": "KUyIvwqxYcG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting catagorical value into object values based on store type class.\n",
        "df['StateHoliday'] = np.where((df['StateHoliday'] == 'b'),1,df['StateHoliday'])\n",
        "df['StateHoliday'] = np.where((df['StateHoliday'] == 'c'),2,df['StateHoliday'])\n",
        "df['StateHoliday'] = np.where((df['StateHoliday'] == 'a'),0,df['StateHoliday'])\n",
        "df['StateHoliday'] = np.where((df['StateHoliday'] == 'd'),3,df['StateHoliday'])"
      ],
      "metadata": {
        "id": "t3YSOKslfgWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting object dtype to integer.\n",
        "df['Year']= df['Year'].astype(int)\n",
        "df['Month']= df['Month'].astype(int)\n",
        "df['StoreType']= df['StoreType'].astype(int)\n",
        "df['Assortment']= df['Assortment'].astype(int)\n",
        "df['StateHoliday'] = df['StateHoliday'].astype(int)"
      ],
      "metadata": {
        "id": "S3nkWKm-Yvk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "\n",
        "# Create a new feature that calculates the total sales per customer\n",
        "df['SalesPerCustomer'] = df['Sales'] / df['Customers']\n",
        "\n",
        "# Create a new feature that calculates the average sales per store per day\n",
        "df['AvgSalesPerStorePerDay'] = df.groupby(['Store', 'DayOfWeek'])['Sales'].transform('mean')\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace missing values in SalesPerCustomer column with the mean value\n",
        "df['SalesPerCustomer'].fillna((df['SalesPerCustomer'].mean()), inplace=True)"
      ],
      "metadata": {
        "id": "KZQi0SdMm3rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "# defining dependent variable\n",
        "dep_var = 'Sales'\n",
        "\n",
        "# defining independent variable\n",
        "indep_var = df.columns.drop(['Store','Sales','Open',])\n"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the data of independent variables\n",
        "X = df[indep_var].values\n",
        "\n",
        "# Create the dependent variable data\n",
        "y = df[dep_var].values"
      ],
      "metadata": {
        "id": "DTpXl7_rXT2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = list(df.describe().columns)"
      ],
      "metadata": {
        "id": "lVwEYIsNWHCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transform Your data\n",
        "#printing displots to analyze the distribution of all numerical features\n",
        "for col in numeric_features[1:-3]:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = np.log1p(df[col])\n",
        "    sns.distplot(feature)    \n",
        "    ax.set_title(col)    \n",
        "    \n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "mvuG6ZC_dgtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "AZJIK4BIXhIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used a test size of 0.2, which means 20% of the data is reserved for testing, and 80% of the data is used for training the model. This is a common splitting ratio in machine learning and is generally considered a good starting point. The reason for reserving some data for testing is to evaluate how well the model generalizes to new, unseen data."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 Linear Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate Metrics\n",
        "def print_evaluate(true, predicted):  \n",
        "    mae = metrics.mean_absolute_error(true, predicted)\n",
        "    mse = metrics.mean_squared_error(true, predicted)\n",
        "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
        "    r2_square = metrics.r2_score(true, predicted)\n",
        "    print('MAE:', mae)\n",
        "    print('MSE:', mse)\n",
        "    print('RMSE:', rmse)\n",
        "    print('R2 Square', r2_square)\n",
        "    print('__________________________________')"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model \n",
        "lin_reg = LinearRegression(normalize=True)\n",
        "lin_reg.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "VwODbZC2RFos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the model\n",
        "pred = lin_reg.predict(X_test)"
      ],
      "metadata": {
        "id": "y3xr-nm8nZZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation Metrics\n",
        "test_pred = lin_reg.predict(X_test)\n",
        "train_pred = lin_reg.predict(X_train)\n",
        "\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)"
      ],
      "metadata": {
        "id": "8FusVMFincWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 Lasso Regression"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "\n",
        "lasso = Lasso(selection='random',random_state=0)\n",
        "parameters = {'alpha': [1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,]}\n",
        "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=5)\n",
        "lasso_regressor.fit(X_train, y_train)\n",
        "\n",
        "test_pred = lasso_regressor.predict(X_test)\n",
        "train_pred = lasso_regressor.predict(X_train)\n",
        "\n",
        "# test the model performance\n",
        "\n",
        "\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "zw=print_evaluate(y_train, train_pred)\n",
        "print('====================================')\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "\n",
        "print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)"
      ],
      "metadata": {
        "id": "rABZBvbAntXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 Ridge Regression"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implement model\n",
        "ridge = Ridge(alpha=0.001, solver='cholesky', tol=0.0001, random_state=42)\n",
        "ridge.fit(X_train, y_train)\n",
        "pred = ridge.predict(X_test)\n",
        "\n",
        "#fit the model\n",
        "test_pred = ridge.predict(X_test)\n",
        "train_pred = ridge.predict(X_train)\n",
        "\n",
        "# test on train data set\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)\n",
        "\n",
        "# test on test dataset\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 4 Random Forest"
      ],
      "metadata": {
        "id": "uJPrtq4u9STc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model implementation\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "param_grid = {  'bootstrap': [True], 'max_depth': [5, 10, None], 'max_features': ['auto', 'log2'], 'n_estimators': [25]}\n",
        "rfr = RandomForestRegressor(random_state = 1)\n",
        "\n",
        "random_forest_model= GridSearchCV(estimator = rfr, param_grid = param_grid, cv = 3, n_jobs = 1, verbose = 0, return_train_score=True)"
      ],
      "metadata": {
        "id": "WhjUqxJe9cgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Fit the object to train dataset\n",
        "random_forest_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "0pY2J4oB9jOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = random_forest_model.predict(X_train)\n",
        "test_pred = random_forest_model.predict(X_test)"
      ],
      "metadata": {
        "id": "A5LhfcUF9mYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test model on train data set\n",
        "\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)"
      ],
      "metadata": {
        "id": "1L8hudSl9puG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test model on test data set\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)"
      ],
      "metadata": {
        "id": "uO8ViDWK9smu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 5 Decision Tree"
      ],
      "metadata": {
        "id": "ZhIrSj5d-ERW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "#implement model\n",
        "DT_model = DecisionTreeRegressor()\n",
        "DT_model.fit(X_train,y_train)\n",
        "\n",
        "#fit the model\n",
        "test_pred = DT_model.predict(X_test)\n",
        "train_pred = DT_model.predict(X_train)\n",
        "\n",
        "# test model on train data set\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)\n",
        "\n",
        "\n",
        "# test model on test data set\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)"
      ],
      "metadata": {
        "id": "n8paHcwp9_2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR=round(lin_reg.score(X_train,y_train)*100,2)\n",
        "Rg=round(ridge.score(X_train,y_train)*100,2)\n",
        "ls2=round(metrics.r2_score(y_train,lasso_regressor.predict(X_train))*100,2)\n",
        "Rf=round(random_forest_model.score(X_train,y_train)*100,2)\n",
        "Dt=round(DT_model.score(X_train,y_train)*100,2)"
      ],
      "metadata": {
        "id": "uJDYzgZ-4kUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models =pd.DataFrame({\n",
        "    'Model': ['Linear_Regression', 'Lasso_Regression','Ridge_Regression',\n",
        "               'Random_Forest', 'Desicion-Tree_Regression'],\n",
        "    'Score': [LR,ls2,Rg,Dt,Rf]})\n",
        "#models.sort_values(by='Score')\n",
        "#models\n",
        "models.sort_values(by='Score',ascending=False)\n"
      ],
      "metadata": {
        "id": "Wgv12gkL38gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusions from EDA**\n",
        "\n",
        "* The most popular assortment levels were \"extra\" and \"extended,\" indicating that most stores stock extra or extended mix types of products.\n",
        "\n",
        "* There is a linear link between customers and sales whenever a promotion is used, suggesting that the majority of customers tend to come on sale days when prices are lower.\n",
        "\n",
        "* Sales were lower on the first days of the month than on the last days, suggesting that individuals tend to shop for the end of the current month and the beginning of the following one, possibly for daily necessities.\n",
        "* Average sales on Monday were higher compared to Sundays, possibly because people tend to do other things rather than shop for their basic necessities or prefer to stay at home on holidays.\n",
        "\n",
        "* School holidays make a big difference in sales, and out of the total percentage of products, a good percentage is meant for school students (i.e., 17.9%).\n",
        "\n",
        "* Where competition was higher, sales were also higher, and vice versa.\n",
        "\n",
        "* Sales were particularly strong in the months of November and December, which were followed by a holiday, suggesting that the majority of individuals are likely Christians."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusions from EDA**\n",
        "\n",
        "* We performed various regression techniques on our dataset to predict outcomes and evaluated their performance using the R2 score.\n",
        "\n",
        "* Among the models, Decision Tree showed better performance with an R2 score of 0.999791.\n",
        "\n",
        "* Random Forest Regression is a powerful algorithm that can handle large datasets efficiently and provide a higher level of accuracy in predicting outcomes compared to other regression algorithms.\n",
        "\n",
        "* Therefore, we conclude that Random Forest Regression is the best model for our dataset and can provide accurate predictions for our target variable.\n",
        "\n"
      ],
      "metadata": {
        "id": "M-NSj-SWmvgj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7fpu4du0ztPp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}